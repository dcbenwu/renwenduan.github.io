---
layout:     post
title:      "Scrapy爬取知乎所有用户实战(下)"
subtitle:   "Scrapy-redis开启分布式爬取"
date:       2017-08-18
author:     "Duanrw"
header-img: "img/post-bg-js-module.jpg"
catalog: true
header-mask: 0.3
tags:
    - 爬虫
    - Scrapy
    - python
    - 分布式
    - Scrapy-redis
---

## Foreword
---

> 当你用scrapy写好一个爬虫后,惬意的坐在凳子上看它在运动,老板走过来...  
老板: 东西做好了吗?  
你: 做好了做好了,每分钟能爬1000条数据.  
老板: 那好,你爬1000~万~条数据给我!  
你: 好好好,没问题!  
老板: 那尽快给我!  
你: 不就1000w吗?我一分钟爬1000条,那就要1000w/1000/60/24= 神马?要7天? 怎么办多进程吧,数据会重复爬取,怎么办怎么办?  还能怎么办,当然是分布式了!  

---

## Catalog
1. Why should we use distributed system?
2. Scrapy-redis analyze  
3. How to use Scrapy-redis  
4. Use the Scrapyd to Deploy the project  

## Why should we use distributed system
从上面的故事也可以看到了,我们有两个需求:
* 快速大规模抓取
* 不重复抓取  

对于多进程来说我们如果同时开启多个进程来运行爬虫那么就会造成数据的重复,对于同以条信息,因为多个个进程之间并不知道是否抓取了这个信息,就会无论如何都会抓取,这样就造成了资源的浪费,也没有提升效率.所以我们要是能改造下scrapy的调度器就好了,这样就会让爬虫同时从一个队列里取用数据!这样就避免了重复,同时也可以开很多进程来运行同一个队列里的请求,然后再将获得的需要处理的请求同时放入调度器,让调度器统一分配!那么这个队列怎么实现呢? **Scrapy-redis** 别人已将造好了轮子了, 我们只要理解下原理然后拿来用就好了!


## Scrapy-redis analyze  
这里引用崔大神的博客来说明Scrapy-redis 的实现原理,先来张图:  

然后上Scrapy-redis设置的分析:

```python
#启用Redis调度存储请求队列
SCHEDULER = "scrapy_redis.scheduler.Scheduler"

#确保所有的爬虫通过Redis去重
DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"

#默认请求序列化使用的是pickle 但是我们可以更改为其他类似的。PS：这玩意儿2.X的可以用。3.X的不能用
#SCHEDULER_SERIALIZER = "scrapy_redis.picklecompat"

#不清除Redis队列、这样可以暂停/恢复 爬取
#SCHEDULER_PERSIST = True

#使用优先级调度请求队列 （默认使用）
#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.PriorityQueue'
#可选用的其它队列
#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.FifoQueue'
#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.LifoQueue'

#最大空闲时间防止分布式爬虫因为等待而关闭
#SCHEDULER_IDLE_BEFORE_CLOSE = 10

#将清除的项目在redis进行处理
ITEM_PIPELINES = {
    'scrapy_redis.pipelines.RedisPipeline': 300
}

#序列化项目管道作为redis Key存储
#REDIS_ITEMS_KEY = '%(spider)s:items'

#默认使用ScrapyJSONEncoder进行项目序列化
#You can use any importable path to a callable object.
#REDIS_ITEMS_SERIALIZER = 'json.dumps'

#指定连接到redis时使用的端口和地址（可选）
#REDIS_HOST = 'localhost'
#REDIS_PORT = 6379

#指定用于连接redis的URL（可选）
#如果设置此项，则此项优先级高于设置的REDIS_HOST 和 REDIS_PORT
#REDIS_URL = 'redis://user:pass@hostname:9001'

#自定义的redis参数（连接超时之类的）
#REDIS_PARAMS  = {}

#自定义redis客户端类
#REDIS_PARAMS['redis_cls'] = 'myproject.RedisClient'

#如果为True，则使用redis的'spop'进行操作。
#如果需要避免起始网址列表出现重复，这个选项非常有用。开启此选项urls必须通过sadd添加，否则会出现类型错误。
#REDIS_START_URLS_AS_SET = False

#RedisSpider和RedisCrawlSpider默认 start_usls 键
#REDIS_START_URLS_KEY = '%(name)s:start_urls'

#设置redis使用utf-8之外的编码
#REDIS_ENCODING = 'latin1'
```
